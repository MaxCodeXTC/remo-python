{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# need to specify path to remo in notebook (for dev purpose only)\n",
    "#local_path_to_repo =  '/Users/vovka/workspace/github.com/remo-python'\n",
    "local_path_to_repo =  '/home/andrea/Desktop/Projects/repo/remo-python'\n",
    "sys.path.insert(0, local_path_to_repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    (\\(\\ \n",
      "    (>':') Remo server is running: v0.3.9-15-g9b08b86a\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import remo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial content:\n",
    "\n",
    "* Populate annotation set manually\n",
    "* Populate annotation set from supported annotation file\n",
    "* TODO: Populate annotation set from custom annotation file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate annotation set manually\n",
    "\n",
    "First we create new dataset and populate it only with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open http://localhost:8123/datasets/21\n"
     ]
    }
   ],
   "source": [
    "urls = ['https://remo-scripts.s3-eu-west-1.amazonaws.com/open_images_sample_dataset.zip']\n",
    "\n",
    "ds = remo.create_dataset(name = 'D1', urls = urls)\n",
    "ds.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![view_dataset.jpeg](assets/view_dataset.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's create new annotation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classes = ['Sky', 'Water', 'Person', 'Dog', 'Cat']\n",
    "annotation_set = ds.create_annotation_set(annotation_task = 'Object detection',\n",
    "                                          name = 'Objects',\n",
    "                                          classes = my_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Annotation set 12 - 'Objects', task: Object detection, #classes: 5"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.default_annotation_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Annotation set 11 - 'Objects', task: Object detection, #classes: 5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_set = ds.annotation_sets()[0]\n",
    "annotation_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can retrieve the lisit of images and easily add some annotations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = ds.images()\n",
    "my_image = images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 885 - 000595fe6fee6369.jpg\n",
      "Resoultion:  1024 x 681\n"
     ]
    }
   ],
   "source": [
    "print(my_image)\n",
    "print('Resoultion: ', my_image.width, 'x', my_image.height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_image.dataset_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Dataset 21 - 'D1'\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: annotation set not defined\n"
     ]
    }
   ],
   "source": [
    "annotation = remo.Annotation()\n",
    "annotation.add_item(classes=['Person'], bbox=[100, 100, 300, 300])\n",
    "annotation.add_item(classes=['Dog'], bbox=[250, 250, 400, 400])\n",
    "my_image.add_annotation(annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation = remo.Annotation()\n",
    "annotation.add_item(classes=['Person'], bbox=[100, 100, 300, 300])\n",
    "annotation.add_item(classes=['Dog'], bbox=[250, 250, 400, 400])\n",
    "annotation_set.add_annotation(my_image.id, annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open http://localhost:8123/image/835?dataset_id=16\n"
     ]
    }
   ],
   "source": [
    "my_image.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![added_annotation.jpeg](assets/added_annotation.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate annotation set from supported annotation file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = remo.task.object_detection\n",
    "name = 'Objects 2'\n",
    "classes = ['Airplane', 'Clothing', 'Dog', 'Fashion accessory', 'Food', 'Footwear', 'Fruit', 'Human arm', 'Human body',\n",
    " 'Human hand', 'Human leg', 'Mammal', 'Man', 'Person', 'Salad', 'Sports equipment', 'Trousers', 'Woman']\n",
    "annotation_set_2 = ds.create_annotation_set(task, name, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Annotation set 3 - 'Objects 2', task: Object detection, #classes: 18"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_set_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'files_link_result': {'files uploaded': 0, 'annotations': 10, 'errors': []}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_files=['/Users/vovka/workspace/github.com/remo-python/examples/assets/open_sample.csv']\n",
    "task = remo.task.object_detection\n",
    "\n",
    "ds.add_data(local_files=annotation_files, annotation_task=task, annotation_set_id=annotation_set_2.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'AnnotationSet ID': 3,\n",
       "  'AnnotationSet name': 'Objects 2',\n",
       "  'n_images': 10,\n",
       "  'n_classes': 18,\n",
       "  'n_objects': 98,\n",
       "  'top_3_classes': [{'name': 'Fruit', 'count': 27},\n",
       "   {'name': 'Sports equipment', 'count': 12},\n",
       "   {'name': 'Human arm', 'count': 10}],\n",
       "  'creation_date': None,\n",
       "  'last_modified_date': '2020-03-02T16:24:04.512738Z'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.get_annotation_statistics(annotation_set_2.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
