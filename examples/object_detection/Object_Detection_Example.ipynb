{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection Tutorial\n",
    "\n",
    "- ~~Pre-process to Remo Format~~\n",
    "- ~~Upload Data to Remo (visualize) (Train / Test / Valid split?)~~\n",
    "- ~~visualize~~\n",
    "- annotation stats\n",
    "- ~~Export from Remo.ai (data + tags) -> Plain CSV~~\n",
    "- ~~Create Unified Dataset for train and test/inference~~\n",
    "- ~~Train Faster RCNN~~\n",
    "- ~~Save model~~\n",
    "- ~~Run inference on test set and save to CSV~~\n",
    "- ~~Upload to Remo (Model Predictions)~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "local_path_to_repo = \"../../remo-python\"\n",
    "sys.path.insert(0, local_path_to_repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import remo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from PIL import Image\n",
    "import csv\n",
    "random.seed(4)\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "import remo\n",
    "remo.set_viewer('jupyter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"wheat_dataset\"\n",
    "images_path = os.path.join(root_dir, \"images\")\n",
    "annotations_path = os.path.join(root_dir, \"annotations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## REQUIRES MERGE OF PULL REQUEST TO RUN\n",
    "\n",
    "im_list = [os.path.basename(i) for i in glob.glob(str(images_path)+\"/**/*.jpg\", recursive=True)]\n",
    "im_list = random.sample(im_list, len(im_list))\n",
    "# Defining the train test split\n",
    "train_idx = round(len(im_list) * 0.4)\n",
    "valid_idx = train_idx + round(len(im_list) * 0.3)\n",
    "test_idx = valid_idx + round(len(im_list) * 0.3)\n",
    "\n",
    "# Tags Dictionary\n",
    "tags_dict = {\"train\" : im_list[0:train_idx], \"valid\" : im_list[train_idx:valid_idx], \"test\" : im_list[valid_idx:test_idx]}\n",
    "\n",
    "# Generating Tags file\n",
    "remo.generate_tags_from_folders(tags_dictionary = tags_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wheat_dataset = remo.create_dataset(name=\"Wheat Dataset\", local_files=[root_dir, \"train_test_valid_split.csv\"], annotation_task= \"Object Detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize images/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wheat_dataset.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wheat_dataset.view_annotation_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wheat_dataset.export_annotations_to_file(\"wheat_dataset.zip\", annotation_format=\"csv\", full_path='true')\n",
    "!unzip wheat_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ObjectDetectionDataset(Dataset):\n",
    "\n",
    "    def __init__(self, annotations, train_test_split, transform=None, mode=\"train\"):\n",
    "        self.mode = mode\n",
    "\n",
    "        self.data = pd.read_csv(annotations)\n",
    "        self.data[\"im_name\"] = self.data[\"file_name\"].apply(lambda x : os.path.basename(x))\n",
    "        self.data = self.data.set_index(\"im_name\")\n",
    "\n",
    "        # Tags for Test Train Split\n",
    "        self.train_test_split = pd.read_csv(train_test_split).set_index(\"file_name\")\n",
    "        self.data[\"tag\"] = -1\n",
    "\n",
    "        # Update Tags using Pandas, Column im_name in self.data is compared to file_name in self.train_test_split \n",
    "        self.data.update(self.train_test_split)\n",
    "        \n",
    "        # Load only Train/Test/Split depending on the mode\n",
    "        self.data = self.data[self.data[\"tag\"] == self.mode].reset_index(drop=True)\n",
    "        \n",
    "        self.file_names = self.data['file_name'].unique()\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.file_names.shape[0]\n",
    "\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "\n",
    "        file_name = self.file_names[index]\n",
    "        records = self.data[self.data['file_name'] == file_name]\n",
    "        \n",
    "        image = np.array(Image.open(file_name), dtype=np.float32)\n",
    "        image /= 255.0\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  \n",
    "            \n",
    "        if self.mode != \"test\":\n",
    "            boxes = records[['xmin', 'ymin', 'xmax', 'ymax']].values\n",
    "            \n",
    "            area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "            area = torch.as_tensor(area, dtype=torch.float32)\n",
    "\n",
    "            labels = torch.ones((records.shape[0],), dtype=torch.int64)\n",
    "            \n",
    "            iscrowd = torch.zeros((records.shape[0],), dtype=torch.int64)\n",
    "            \n",
    "            target = {}\n",
    "\n",
    "            target['boxes'] = boxes\n",
    "            target['labels'] = labels\n",
    "            target['image_id'] = torch.tensor([index])\n",
    "            target['area'] = area\n",
    "            target['iscrowd'] = iscrowd \n",
    "            target['boxes'] = torch.stack(list((map(torch.tensor, target['boxes'])))).type(torch.float32)\n",
    "\n",
    "            return image, target, file_name\n",
    "        else:\n",
    "            return image, file_name\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensor_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = ObjectDetectionDataset(annotations=\"Object detection.csv\",  \n",
    "                                      train_test_split=\"tags.csv\", \n",
    "                                      transform=tensor_transform, \n",
    "                                      mode=\"train\")\n",
    "\n",
    "test_dataset = ObjectDetectionDataset(annotations=\"Object detection.csv\", \n",
    "                                      train_test_split=\"tags.csv\", \n",
    "                                      transform=tensor_transform, \n",
    "                                      mode=\"test\")\n",
    "                                      \n",
    "valid_dataset = ObjectDetectionDataset(annotations=\"Object detection.csv\",\n",
    "                                       train_test_split=\"tags.csv\", \n",
    "                                       transform=tensor_transform, \n",
    "                                       mode=\"valid\")\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=1, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "valid_data_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=0, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "lr_scheduler = None\n",
    "\n",
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_value = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    train_data_loader = tqdm.tqdm(train_data_loader)\n",
    "    for images, targets, image_ids in train_data_loader:\n",
    "        \n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        loss_value = losses.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()    \n",
    "    # update the learning rate\n",
    "    if lr_scheduler is not None:\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    print(f\"\\n Epoch #{epoch} loss: {loss_value}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'fasterrcnn_resnet50_fpn.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Predictions and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, pretrained_backbone=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "num_classes = 2  # 1 class (wheat) + background\n",
    "\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "model.load_state_dict(torch.load('fasterrcnn_resnet50_fpn.pth'))\n",
    "model.eval()\n",
    "\n",
    "x = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "detection_threshold = 0.6\n",
    "results = []\n",
    "\n",
    "test_data_loader = tqdm.tqdm(test_data_loader)\n",
    "\n",
    "for images, image_ids in test_data_loader:\n",
    "\n",
    "    images = list(image.to(device) for image in images)\n",
    "    outputs = model(images)\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "\n",
    "        boxes = outputs[i]['boxes'].data.cpu().numpy()\n",
    "        scores = outputs[i]['scores'].data.cpu().numpy()\n",
    "        boxes = boxes[scores >= detection_threshold].astype(np.int32)\n",
    "        scores = scores[scores >= detection_threshold]\n",
    "        image_id = image_ids[i]\n",
    "        for box in boxes:\n",
    "            results.append({\"file_name\" : os.path.basename(image_id), \"classes\" : 0, \"xmin\" : box[0], \"ymin\" : box[1], \n",
    "                                \"xmax\" : box[2], \"ymax\" : box[3]})\n",
    "\n",
    "with open('results.csv', 'w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=[\"file_name\", \"classes\", \"xmin\", \"ymin\", \"xmax\", \"ymax\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wheat_dataset.create_annotation_set(\"Object Detection\", name=\"model_predictions\", path_to_annotation_file=\"./results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wheat_dataset.view()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('pt_36': conda)",
   "language": "python",
   "name": "python_defaultSpec_1597145970579"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}