{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we explore some different options to upload annotations in Remo. We will:\n",
    "\n",
    "- add annotations from a file in a format supported by remo\n",
    "- add annotations from code, which enables uploading annotations from any input format\n",
    "- introduce the concept of Annotation Sets, for finer control over annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start off by creating a dataset and populating it with some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    (\\(\\ \n",
      "    (>':') Remo server is running: v0.3.10-77-g3ab8aa16\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "# need to specify path to remo in notebook\n",
    "local_path_to_repo =  '/home/andrea/Desktop/Projects/repo/remo-python'\n",
    "sys.path.insert(0, local_path_to_repo)\n",
    "\n",
    "import remo\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "urls = ['https://remo-scripts.s3-eu-west-1.amazonaws.com/open_images_sample_dataset.zip']\n",
    "my_dataset = remo.create_dataset(name = 'D1', urls = urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add annotations stored in a file supported by remo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding annotations from a file supported by Remo just requires passing the file via `add_data` method and specify the task.**\n",
    "\n",
    "Remo is able to automatically parse annotations in JSON, CSV, XML in a variety of formats (such as Pascal, CoCo, Open Images, etc). You can read more about file formats supported by remo in [our documentation](https://remo.ai/docs/annotation-formats/).\n",
    "\n",
    "**As an example, let's see how to add some annotations for an Object Detection task from a CSV file with encoded classes**\n",
    "\n",
    "In this case, annotations are stored in a CSV file in a format already supported by Remo. Class labels were encoded using [GoogleKnowledgeGraph](https://developers.google.com/knowledge-graph). Remo automatically detects the class encoding and translates it into the corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ImageID', 'Source', 'LabelName', 'Confidence', 'XMin', 'XMax', 'YMin',\n",
       "       'YMax', 'IsOccluded', 'IsTruncated', 'IsGroupOf', 'IsDepiction',\n",
       "       'IsInside'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_files=[os.getcwd() + '/assets/open_sample.csv']\n",
    "\n",
    "df = pd.read_csv(annotation_files[0])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'files_link_result': {'files uploaded': 0, 'annotations': 9, 'errors': []}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset.add_data(local_files=annotation_files, annotation_task = 'Object detection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see annotation statistics, explore the dataset and further leverage Remo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'AnnotationSet ID': 15,\n",
       "  'AnnotationSet name': 'Object detection',\n",
       "  'n_images': 9,\n",
       "  'n_classes': 15,\n",
       "  'n_objects': 84,\n",
       "  'top_3_classes': [{'name': 'Fruit', 'count': 27},\n",
       "   {'name': 'Sports equipment', 'count': 12},\n",
       "   {'name': 'Mammal', 'count': 7}],\n",
       "  'creation_date': None,\n",
       "  'last_modified_date': '2020-03-15T19:48:48.983671Z'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset.get_annotation_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open http://localhost:8123/datasets/11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            id=\"remo_frame_901a61a5-01ea-4f4b-9794-110cb25c5f0f\"\n",
       "            width=\"100%\"\n",
       "            height=\"100px\"\n",
       "            src=\"http://localhost:8123/datasets/11?allheadless\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        <script type=\"text/javascript\">\n",
       "            (function () {\n",
       "                const iframe = document.getElementById(\"remo_frame_901a61a5-01ea-4f4b-9794-110cb25c5f0f\");\n",
       "                let timeout, delay = 100;\n",
       "            \n",
       "                const setHeight = () => {\n",
       "                  const width = iframe.clientWidth;\n",
       "                  iframe.style.height = (width * screen.height / screen.width) * 0.8 + 'px';\n",
       "                }\n",
       "                window.addEventListener(\"resize\", () => {\n",
       "                    clearTimeout(timeout);\n",
       "                  // start timing for event \"completion\"\n",
       "                  timeout = setTimeout(setHeight, delay);\n",
       "                });\n",
       "                setHeight();\n",
       "            })()\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dataset_added_annotation.jpeg](assets/dataset_added_annotation.jpeg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add annotations from code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case your annotations are in a custom format, it's still very easy to upload annotations from code (as long as the task is one of those currently supported by Remo).\n",
    "\n",
    "**As an example, let's see how we can add annotations to a specific image from code**\n",
    "\n",
    "This can be useful for instance to add model predictions as annotations or to tag specific images.\n",
    "\n",
    "First, let's retrieve one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 1457 - 000a1249af2bc5f0.jpg\n",
      "Resoultion:  1024 x 678\n"
     ]
    }
   ],
   "source": [
    "images = my_dataset.images()\n",
    "my_image = images[1]\n",
    "print(my_image)\n",
    "print('Resoultion: ', my_image.width, 'x', my_image.height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we can easily add annotations using `add_annotations()` method of the dataset class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress 100% - 1/1 - elapsed 0:00:01.001000 - speed: 1.00 img / s, ETA: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "annotations = []\n",
    "\n",
    "annotation = remo.Annotation()\n",
    "annotation.img_filename = my_image.name\n",
    "annotation.classes='Human hand'\n",
    "annotation.bbox=[227, 284, 678, 674]\n",
    "annotations.append(annotation)\n",
    "\n",
    "annotation = remo.Annotation()\n",
    "annotation.img_filename = my_image.name\n",
    "annotation.classes='Fashion accessory'\n",
    "annotation.bbox=[496, 322, 544,370]\n",
    "annotations.append(annotation)\n",
    "\n",
    "my_dataset.add_annotations(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open http://localhost:8123/image/1457?dataset_id=11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            id=\"remo_frame_143b03d4-cd6a-492e-8bc7-fdcd8cc29a52\"\n",
       "            width=\"100%\"\n",
       "            height=\"100px\"\n",
       "            src=\"http://localhost:8123/image/1457?dataset_id=11&allheadless\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        <script type=\"text/javascript\">\n",
       "            (function () {\n",
       "                const iframe = document.getElementById(\"remo_frame_143b03d4-cd6a-492e-8bc7-fdcd8cc29a52\");\n",
       "                let timeout, delay = 100;\n",
       "            \n",
       "                const setHeight = () => {\n",
       "                  const width = iframe.clientWidth;\n",
       "                  iframe.style.height = (width * screen.height / screen.width) * 0.8 + 'px';\n",
       "                }\n",
       "                window.addEventListener(\"resize\", () => {\n",
       "                    clearTimeout(timeout);\n",
       "                  // start timing for event \"completion\"\n",
       "                  timeout = setTimeout(setHeight, delay);\n",
       "                });\n",
       "                setHeight();\n",
       "            })()\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset.view_image(my_image.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case your input data is in a custom file, you can write a parser to load annotations using the Annotation object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotation sets represent a collection of annotations for all the images within a Dataset.\n",
    "An annotation set is characterized by a task (such as 'Object Detection') and a list of classes.\n",
    "\n",
    "The advantage of grouping annotations in an Annotation Set is that it allows for high-level group operations on all the annotations, such:\n",
    "- grouping classes together\n",
    "- deleting objects of specific classes\n",
    "- comparing of different annotations (such as ground truth vs prediction, or annotations coming from different annotators)\n",
    "\n",
    "\n",
    "**Let's first create an empty annotation set with a predetermined list of classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classes = ['Airplane', 'Clothing', 'Dog', 'Fashion accessory', 'Food', 'Footwear', 'Fruit', 'Human arm', \n",
    "         'Human body', 'Human hand', 'Human leg', 'Mammal', 'Man', 'Person', 'Salad', 'Sports equipment', 'Trousers', 'Woman']\n",
    "\n",
    "annotation_set = my_dataset.create_annotation_set(annotation_task = 'Object detection',\n",
    "                                          name = 'Objects',\n",
    "                                          classes = my_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily retrieve different annotation sets of a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Annotation set 17 - 'Objects', task: Object detection, #classes: 18]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset.annotation_sets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add annotations from supported file format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your annotations are already in a format supported by Remo, you can upload them right away using\n",
    "my_dataset.add_data().\n",
    "\n",
    "**As an example, let's see how to add some annotations from a CSV file**\n",
    "\n",
    "In thiss case, annotations are stored in a CSV file in a format already supported by Remo. Class labels were encoded using [GoogleKnowledgeGraph](https://developers.google.com/knowledge-graph)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When adding the file to the annotation set, remo automatically: \n",
    "- detects the class encoding and translates it into the corresponding labels\n",
    "- only adds annotations for classes that are part of the existing annotation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add annotations from custom formats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
