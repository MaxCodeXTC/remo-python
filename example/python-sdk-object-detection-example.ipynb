{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# MC: need to specify path to remo in notebook\n",
    "# mac version\n",
    "local_path_to_repo =  '/Users/melodi/remo-python'\n",
    "# windows version\n",
    "#local_path_to_repo =  'C:/Users/crows/Documents/GitHub/remo-python'\n",
    "\n",
    "sys.path.insert(0, local_path_to_repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    (\\(\\ \n",
      "    (>':') Remo server is running: {'version': '0.3.4'}\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import remo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dataset 1 - 'Vova's dataset',\n",
       " Dataset 2 - 'open images detection',\n",
       " Dataset 3 - 'Subset of OID',\n",
       " Dataset 4 - 'train',\n",
       " Dataset 6 - 'test',\n",
       " Dataset 12 - 'oid 100',\n",
       " Dataset 13 - 'open images sample data',\n",
       " Dataset 19 - 'oid building ',\n",
       " Dataset 21 - 'oid building and car',\n",
       " Dataset 22 - 'oid building car detection',\n",
       " Dataset 25 - 'open images data',\n",
       " Dataset 26 - 'oid car',\n",
       " Dataset 28 - 'oid car and person',\n",
       " Dataset 29 - 'test upload']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remo.list_datasets() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset = remo.get_dataset(28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Annotation set 19 - 'Object Detection Actual', task: Object detection, #classes: 5,\n",
       " Annotation set 24 - 'Classification Predictions', task: Image classification, #classes: 2]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset.list_annotation_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = my_dataset[0:len(my_dataset) // 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = my_dataset[len(my_dataset) // 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.export_annotation_to_csv('val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.export_annotation_to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>039b687dbee6ec4a.jpg</td>\n",
       "      <td>/m/01g317</td>\n",
       "      <td>103.863296</td>\n",
       "      <td>283.794432</td>\n",
       "      <td>226.743296</td>\n",
       "      <td>588.800256</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>039b687dbee6ec4a.jpg</td>\n",
       "      <td>/m/01g317</td>\n",
       "      <td>383.268864</td>\n",
       "      <td>212.845824</td>\n",
       "      <td>558.811136</td>\n",
       "      <td>626.833920</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>039b687dbee6ec4a.jpg</td>\n",
       "      <td>/m/01g317</td>\n",
       "      <td>542.720000</td>\n",
       "      <td>273.553920</td>\n",
       "      <td>664.868864</td>\n",
       "      <td>629.760000</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>039b687dbee6ec4a.jpg</td>\n",
       "      <td>/m/01g317</td>\n",
       "      <td>683.154432</td>\n",
       "      <td>242.102784</td>\n",
       "      <td>811.154432</td>\n",
       "      <td>632.686080</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>039b687dbee6ec4a.jpg</td>\n",
       "      <td>/m/01g317</td>\n",
       "      <td>733.623296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1023.268864</td>\n",
       "      <td>767.268864</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              file_name      class        xmin        ymin         xmax  \\\n",
       "0  039b687dbee6ec4a.jpg  /m/01g317  103.863296  283.794432   226.743296   \n",
       "1  039b687dbee6ec4a.jpg  /m/01g317  383.268864  212.845824   558.811136   \n",
       "2  039b687dbee6ec4a.jpg  /m/01g317  542.720000  273.553920   664.868864   \n",
       "3  039b687dbee6ec4a.jpg  /m/01g317  683.154432  242.102784   811.154432   \n",
       "4  039b687dbee6ec4a.jpg  /m/01g317  733.623296    0.000000  1023.268864   \n",
       "\n",
       "         ymax  height  width  \n",
       "0  588.800256     768   1024  \n",
       "1  626.833920     768   1024  \n",
       "2  629.760000     768   1024  \n",
       "3  632.686080     768   1024  \n",
       "4  767.268864     768   1024  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert annotation format into .xml for darknet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_row(row, class_name='car', root_path='/Users/melodi/Docs/images/'):\n",
    "    class_codes = {'/m/01g317':'Person', '/m/0k4j':'Car'}\n",
    "    vals = ('train', row['file_name'], root_path + row['file_name'], str(row['width']), str(row['height']),)\n",
    "    for i in range(len(row['class'])):\n",
    "        vals = vals + (class_codes[row['class'][i]].lower(),str(row['xmin'][i]), str(row['ymin'][i]), str(row['xmax'][i]), str(row['ymax'][i]),)\n",
    "    \n",
    "    result = \"\"\"<annotation>\n",
    "    <folder>%s</folder>\n",
    "    <filename>%s</filename>\n",
    "    <path>%s</path>\n",
    "    <source>\n",
    "        <database>Unknown</database>\n",
    "    </source>\n",
    "    <size>\n",
    "        <width>%s</width>\n",
    "        <height>%s</height>\n",
    "        <depth>3</depth>\n",
    "    </size>\n",
    "    <segmented>0</segmented>\n",
    "    \"\"\" + \"\"\"<object>\n",
    "        <name>%s</name>\n",
    "        <pose>Unspecified</pose>\n",
    "        <truncated>0</truncated>\n",
    "        <difficult>0</difficult>\n",
    "        <bndbox>\n",
    "            <xmin>%s</xmin>\n",
    "            <ymin>%s</ymin>\n",
    "            <xmax>%s</xmax>\n",
    "            <ymax>%s</ymax>\n",
    "        </bndbox>\n",
    "    </object>\"\"\" * len(row['class']) +\"\"\"\n",
    "</annotation>\n",
    "\"\"\" \n",
    "    result = result % vals\n",
    "    filename = row['file_name'].split('.')[0]\n",
    "    path = '/Users/melodi/Docs/annots/' + filename\n",
    "    f =  open(path + \".xml\", \"w\")\n",
    "    f.write(result)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will group by file_name and aggreagate in a list in the case of multiple objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df.groupby('file_name')['class'].apply(list).reset_index(name='class')\n",
    "for column in df.columns[2:]:\n",
    "    df_new = df.groupby('file_name')[column].apply(list).reset_index(name=column)\n",
    "    df_grouped = df_grouped.merge(df_new, on=['file_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# height and width is the same\n",
    "df_grouped['height'] = df_grouped['height'].apply(lambda x: x[0])\n",
    "df_grouped['width'] = df_grouped['width'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>039b687dbee6ec4a.jpg</td>\n",
       "      <td>/m/01g317</td>\n",
       "      <td>103.863296</td>\n",
       "      <td>283.794432</td>\n",
       "      <td>226.743296</td>\n",
       "      <td>588.800256</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>039b687dbee6ec4a.jpg</td>\n",
       "      <td>/m/01g317</td>\n",
       "      <td>383.268864</td>\n",
       "      <td>212.845824</td>\n",
       "      <td>558.811136</td>\n",
       "      <td>626.833920</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>039b687dbee6ec4a.jpg</td>\n",
       "      <td>/m/01g317</td>\n",
       "      <td>542.720000</td>\n",
       "      <td>273.553920</td>\n",
       "      <td>664.868864</td>\n",
       "      <td>629.760000</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>039b687dbee6ec4a.jpg</td>\n",
       "      <td>/m/01g317</td>\n",
       "      <td>683.154432</td>\n",
       "      <td>242.102784</td>\n",
       "      <td>811.154432</td>\n",
       "      <td>632.686080</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>039b687dbee6ec4a.jpg</td>\n",
       "      <td>/m/01g317</td>\n",
       "      <td>733.623296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1023.268864</td>\n",
       "      <td>767.268864</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              file_name      class        xmin        ymin         xmax  \\\n",
       "0  039b687dbee6ec4a.jpg  /m/01g317  103.863296  283.794432   226.743296   \n",
       "1  039b687dbee6ec4a.jpg  /m/01g317  383.268864  212.845824   558.811136   \n",
       "2  039b687dbee6ec4a.jpg  /m/01g317  542.720000  273.553920   664.868864   \n",
       "3  039b687dbee6ec4a.jpg  /m/01g317  683.154432  242.102784   811.154432   \n",
       "4  039b687dbee6ec4a.jpg  /m/01g317  733.623296    0.000000  1023.268864   \n",
       "\n",
       "         ymax  height  width  \n",
       "0  588.800256     768   1024  \n",
       "1  626.833920     768   1024  \n",
       "2  629.760000     768   1024  \n",
       "3  632.686080     768   1024  \n",
       "4  767.268864     768   1024  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      None\n",
       "1      None\n",
       "2      None\n",
       "3      None\n",
       "4      None\n",
       "       ... \n",
       "129    None\n",
       "130    None\n",
       "131    None\n",
       "132    None\n",
       "133    None\n",
       "Length: 134, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped.apply(convert_row,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Darknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from darkflow.net.build import TFNet\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\"model\": \"/Users/melodi/remo-python/cfg/yolov2.cfg\", \n",
    "           \"load\": \"/Users/melodi/remo-python/bin/yolov2.weights\",\n",
    "           \"batch\": 40,\n",
    "           \"epoch\": 1,\n",
    "           \"train\": True,\n",
    "           \"verbalise\": False,\n",
    "           \"annotation\": \"/Users/melodi/Docs/annots/\",\n",
    "           \"dataset\": \"/Users/melodi/Docs/images/\",\n",
    "           \"labels\": \"/Users/melodi/remo-python/labels.txt\",\n",
    "          \"backup\": \"/Users/melodi/remo-python/ckpt/\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing /Users/melodi/Docs/remo-python/cfg/yolov2.cfg\n",
      "Loading /Users/melodi/Docs/remo-python/bin/yolov2.weights ...\n",
      "Successfully identified 203934260 bytes\n",
      "Finished in 1.413050889968872s\n",
      "/Users/melodi/Docs/remo-python/cfg/yolov2.cfg loss hyper-parameters:\n",
      "\tH       = 19\n",
      "\tW       = 19\n",
      "\tbox     = 5\n",
      "\tclasses = 80\n",
      "\tscales  = [1.0, 5.0, 1.0, 1.0]\n",
      "WARNING:tensorflow:From /Users/melodi/opt/anaconda3/lib/python3.7/site-packages/darkflow/net/yolov2/train.py:87: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "Building /Users/melodi/Docs/remo-python/cfg/yolov2.cfg loss\n",
      "WARNING:tensorflow:From /Users/melodi/opt/anaconda3/lib/python3.7/site-packages/darkflow/net/yolov2/train.py:107: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "INFO:tensorflow:Summary name /Users/melodi/Docs/remo-python/cfg/yolov2.cfg loss is illegal; using Users/melodi/Docs/remo-python/cfg/yolov2.cfg_loss instead.\n",
      "WARNING:tensorflow:From /Users/melodi/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/melodi/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "tfnet = TFNet(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/melodi/Docs/remo-python/cfg/yolov2.cfg parsing /Users/melodi/Docs/annots/\n",
      "Parsing for ['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'] \n",
      "[====================>]100%  09e3c15d734763b1.xml\n",
      "Statistics:\n",
      "car: 194\n",
      "person: 296\n",
      "Dataset size: 134\n",
      "Dataset of 134 instance(s)\n"
     ]
    }
   ],
   "source": [
    "tfnet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing /Users/melodi/Docs/remo-python/cfg/yolov2.cfg\n",
      "Loading None ...\n",
      "Finished in 0.00019788742065429688s\n",
      "INFO:tensorflow:Restoring parameters from /Users/melodi/Docs/remo-python/ckpt/yolov2-3\n"
     ]
    }
   ],
   "source": [
    "options = {\n",
    " \"model\": \"/Users/melodi/remo-python/cfg/yolov2.cfg\", \n",
    "   \"load\": 3,\n",
    " 'threshold': 0.5,\n",
    "    \"verbalise\": False,\n",
    "    \"labels\": \"/Users/melodi/remo-python/labels.txt\",\n",
    "  \"backup\": \"/Users/melodi/remo-python/ckpt/\"}\n",
    "\n",
    "tfnet2 = TFNet(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/melodi/Docs/remo-python/ckpt/yolov2-3\n"
     ]
    }
   ],
   "source": [
    "tfnet2.load_from_ckpt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Predictions in Remo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We feed our validation set into the model and prepare the results to upload Remo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "cars = os.listdir('/Users/melodi/remo-python/val/Car')\n",
    "results = []\n",
    "for img_file in cars:\n",
    "    original_img = cv2.imread('/Users/melodi/remo-python/val/Car/'+img_file)\n",
    "    original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n",
    "    outputs = tfnet2.return_predict(original_img)\n",
    "    result = {'file_name':img_file, 'objects':outputs}\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = os.listdir('/Users/melodi/remo-python/val/Person')\n",
    "for img_file in people:\n",
    "    original_img = cv2.imread('/Users/melodi/remo-python/val/Person/'+img_file)\n",
    "    original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n",
    "    outputs = tfnet2.return_predict(original_img)\n",
    "    result = {'file_name':img_file, 'objects':outputs}\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each output consists to a dictionary containing file_name and objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': '0004d295cfb46842.jpg',\n",
       " 'objects': [{'label': 'person',\n",
       "   'confidence': 0.7596794,\n",
       "   'topleft': {'x': 858, 'y': 411},\n",
       "   'bottomright': {'x': 927, 'y': 607}},\n",
       "  {'label': 'car',\n",
       "   'confidence': 0.53090864,\n",
       "   'topleft': {'x': 166, 'y': 409},\n",
       "   'bottomright': {'x': 249, 'y': 451}},\n",
       "  {'label': 'car',\n",
       "   'confidence': 0.78686273,\n",
       "   'topleft': {'x': 547, 'y': 423},\n",
       "   'bottomright': {'x': 668, 'y': 484}},\n",
       "  {'label': 'car',\n",
       "   'confidence': 0.6657906,\n",
       "   'topleft': {'x': 747, 'y': 424},\n",
       "   'bottomright': {'x': 901, 'y': 499}}]}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will convert this into dataframe in order to feed into Remo as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d = {'person':'/m/01g317', 'car':'/m/0k4j'}\n",
    "df = pd.DataFrame(columns=['file_name','class','xmin','ymin','xmax','ymax'])\n",
    "for res in results:\n",
    "    for i in range(len(res['objects'])):\n",
    "        df.loc[len(df)+1] = [res['file_name'],d.get(res['objects'][i]['label']),res['objects'][i]['topleft']['x'],res['objects'][i]['topleft']['y'], res['objects'][i]['bottomright']['x'], res['objects'][i]['bottomright']['y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0004d295cfb46842.jpg</td>\n",
       "      <td>/m/01g317</td>\n",
       "      <td>858</td>\n",
       "      <td>411</td>\n",
       "      <td>927</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0004d295cfb46842.jpg</td>\n",
       "      <td>/m/0k4j</td>\n",
       "      <td>166</td>\n",
       "      <td>409</td>\n",
       "      <td>249</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0004d295cfb46842.jpg</td>\n",
       "      <td>/m/0k4j</td>\n",
       "      <td>547</td>\n",
       "      <td>423</td>\n",
       "      <td>668</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0004d295cfb46842.jpg</td>\n",
       "      <td>/m/0k4j</td>\n",
       "      <td>747</td>\n",
       "      <td>424</td>\n",
       "      <td>901</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>006cc2c07c881fe0.jpg</td>\n",
       "      <td>/m/01g317</td>\n",
       "      <td>711</td>\n",
       "      <td>221</td>\n",
       "      <td>752</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              file_name      class xmin ymin xmax ymax\n",
       "1  0004d295cfb46842.jpg  /m/01g317  858  411  927  607\n",
       "2  0004d295cfb46842.jpg    /m/0k4j  166  409  249  451\n",
       "3  0004d295cfb46842.jpg    /m/0k4j  547  423  668  484\n",
       "4  0004d295cfb46842.jpg    /m/0k4j  747  424  901  499\n",
       "5  006cc2c07c881fe0.jpg  /m/01g317  711  221  752  326"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the other classes different than car and person.\n",
    "df = df.dropna(subset=['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will upload this .csv file into Remo dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/Users/melodi/Docs/remo-python/example/detection_preds_encoded.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
